---
layout: pacemaker
title: RHEL 7 Quickstart
---
	<section id="main">
	  {% include quickstart-common.html %}

	  <h1>RHEL 7</h1>
	  <h2>Install</h2>
	  <p>
	    Pacemaker ships as part of the Red Hat
	    <a href="https://www.redhat.com/en/resources/high-availability-add-datasheet">High Availability Add-on</a>.
	    The easiest way to try it out on RHEL is to install it from the
	    <a href="https://scientificlinux.org/">Scientific Linux</a>
	    or <a href="https://www.centos.org/">CentOS</a> repositories.
	  </p>
	  <p>
	    If you are already running CentOS or Scientific Linux, you can skip this step.  Otherwise, to teach the machine where to find the CentOS packages, run:
	  </p>
	  <p class="command">
[ALL] # cat <<EOF > /etc/yum.repos.d/centos.repo
[centos-7-base]
name=CentOS-$releasever - Base
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os
#baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/
enabled=1
EOF
	    </p>
	  <p>
	    Next we use yum to install pacemaker and some other
	    necessary packages we will need:
	  </p>
	  <p class="command">
[ALL] # yum install pacemaker pcs resource-agents
	  </p>

	  <h2>Create the Cluster</h2>
	  <p>
	    The supported stack on RHEL7 is based on Corosync 2, so thats
	    what Pacemaker uses too.
	  </p>

	  <p>
	    First make sure that <strong>pcs daemon</strong> is running on every node:
	  </p>
	  <p class="command">
	    [ALL] # systemctl start pcsd.service
	    [ALL] # systemctl enable pcsd.service
	  </p>

	  <p>
	    Then we set up the authentication needed for <strong>pcs</strong>.
	  </p>
	  <p class="command">
[ALL] # echo CHANGEME | passwd --stdin hacluster
[ONE] # pcs cluster auth node1 node2 -u hacluster -p CHANGEME --force
	  </p>

	  <p>
	    We now create a cluster and populate it with some nodes.
	    Note that the name cannot exceed 15 characters (we'll use
	    'pacemaker1').
	  </p>
	  <p class="command">
[ONE] # pcs cluster setup --force --name pacemaker1 node1 node2
	  </p>

	  <h2>Start the Cluster</h2>
          <p class="command">
[ONE] # pcs cluster start --all
	  </p>

	  <h2>Set Cluster Options</h2>
	  <p>
	    With so many devices and possible topologies, it is nearly
	    impossible to include Fencing in a document like this.
	    For now we will disable it.
	  </p>
	  <p class="command">
[ONE] # pcs property set stonith-enabled=false
	  </p>
	  <p>
	    One of the most common ways to deploy Pacemaker is in a
	    2-node configuration.  However quorum as a concept makes
	    no sense in this scenario (because you only have it when
	    more than half the nodes are available), so we'll disable
	    it too.
	  </p>
	  <p class="command">
[ONE] # pcs property set no-quorum-policy=ignore
	  </p>
	  <p>
	    For demonstration purposes, we will force the cluster to
	    move services after a single failure:
	  </p>
	  <p class="command">
[ONE] # pcs resource defaults migration-threshold=1
	  </p>

	  <h2>Add a Resource</h2>
	  <p>
	    Lets add a cluster service, we'll choose one doesn't
	    require any configuration and works everywhere to make
	    things easy.  Here's the command:
	  </p>
	  <p class="command">
[ONE] # pcs resource create my_first_svc Dummy op monitor interval=120s
	  </p>
	  <p>
	    "<strong>my_first_svc</strong>" is the name the service
	    will be known as.
	  </p>
	  <p>
	    "<strong>ocf:pacemaker:Dummy</strong>" tells Pacemaker
	    which script to use
	    (<a href="https://github.com/ClusterLabs/pacemaker/blob/master/extra/resources/Dummy">Dummy</a>
	    - an agent that's useful as a template and for guides like
	    this one), which namespace it is in (pacemaker) and what
	    standard it conforms to
	    (<a href="/pacemaker/doc/en-US/Pacemaker/1.1-pcs/html/Pacemaker_Explained/s-resource-supported.html#_open_cluster_framework">OCF</a>).
	  </p>
	  <p>
	    "<strong>op monitor interval=120s</strong>" tells Pacemaker to
	    check the health of this service every 2 minutes by
	    calling the agent's <strong>monitor</strong> action.
	  </p>
	  <p>
	    You should now be able to see the service running using:
	  </p>
          <p class="command">
[ONE] # pcs status
	  </p>
	  <p>
	    or
	  </p>
          <p class="command">
[ONE] # crm_mon -1
	  </p>

	  <h2>Simulate a Service Failure</h2>
	  <p>
	    We can simulate an error by telling the service to stop
	    directly (without telling the cluster):
	  </p>
	  <p class="command">
[ONE] # crm_resource --resource my_first_svc --force-stop
	  </p>
	  <p>
	    If you now run <strong>crm_mon</strong> in interactive
	    mode (the default), you should see (within the monitor
	    interval of 2 minutes) the cluster notice
	    that <strong>my_first_svc</strong> failed and move it to
	    another node.
	  </p>
	  <h2>Next Steps</h2>
	  <p>
	    <ul>
	      <li>Configure <a href="/pacemaker/doc/en-US/Pacemaker/1.1-pcs/html/Clusters_from_Scratch/ch09.html">Fencing</a></li>
	      <li>Add more services - see <a href="/pacemaker/doc/en-US/Pacemaker/1.1-pcs/html/Clusters_from_Scratch/ch06.html">Clusters from Scratch</a> for examples of how to add IP address, Apache and DRBD to a cluster</li>
	      <li>Learn how to make services <a href="/pacemaker/doc/en-US/Pacemaker/1.1-pcs/html/Clusters_from_Scratch/_specifying_a_preferred_location.html">prefer a specific host</a></li>
	      <li>Learn how to make services <a href="/pacemaker/doc/en-US/Pacemaker/1.1-pcs/html/Clusters_from_Scratch/_ensuring_resources_run_on_the_same_host.html">run on the same host</a></li>
	      <li>Learn how to make services <a href="/pacemaker/doc/en-US/Pacemaker/1.1-pcs/html/Clusters_from_Scratch/_controlling_resource_start_stop_ordering.html">start and stop</a> in a specific order</li>
	      <li>Find out what else Pacemaker can do - see <a href="/pacemaker/doc/en-US/Pacemaker/1.1-pcs/html/Pacemaker_Explained/index.html">Pacemaker Explained</a> for an comprehensive list of concepts and options</li>
	    </ul>
	  </p>


	</section>
